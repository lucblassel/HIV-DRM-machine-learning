{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import balanced_accuracy_score, adjusted_mutual_info_score, brier_score_loss, mutual_info_score, accuracy_score\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"../data\"\n",
    "all_preds_path = os.path.join(data_dir, \"results\", \"Alternate_target_results\", \"all_preds.tsv.gz\")\n",
    "uk_metadata_path = os.path.join(data_dir, \"UK_dataset\", \"metadata.tsv.gz\")\n",
    "africa_metadata_path = os.path.join(data_dir, \"African_dataset\", \"metadata.tsv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'whole_dataset_multi_targets'\n",
    "if not os.path.isdir(dirname):\n",
    "    os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/HIV/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.concat([\n",
    "    pd.read_csv(path, sep=\"\\t\", index_col=0)\n",
    "    for path in [uk_metadata_path, africa_metadata_path]\n",
    "])\n",
    "metadata.index = metadata.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = ['task', 'target', 'dataset', 'subtype', 'shorthand']\n",
    "task_order = ['all features\\nkept', 'DRM features\\nremoved']\n",
    "target_order = ['encoded_label', 'hasDRM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning / gathering\n",
    "You can skip this ig the avove cells read precomputed tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_preds = pd.read_csv(os.path.join(dirname, 'all_preds.tsv'), sep='\\t', index_col=0)\n",
    "all_preds = pd.read_csv(all_preds_path, sep='\\t', index_col=0)\n",
    "all_preds['shorthand'] = all_preds['shorthand'].apply(lambda x: {'B1': 'FC'}.get(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_preds = all_preds[\n",
    "                (all_preds['task'].isin(task_order)) & \n",
    "                (\n",
    "                    ((all_preds['dataset'] == 'UK') & (all_preds['subtype'].isin(['B', 'C']))) |\n",
    "                    ((all_preds['dataset'] == 'Africa') & (all_preds['subtype'] == 'ALL'))\n",
    "                )\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = pd.concat(\n",
    "#     [pd.read_csv(os.path.join('/Users/lucblassel/Documents/Work/hiv-drm-detection/data_pre_split',name), sep='\\t', index_col=0)\n",
    "#     for name in ['uk-metadata.tsv', 'africa-metadata.tsv']]\n",
    "# )\n",
    "# metadata.index = metadata.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_preds.index = subset_preds.index.astype(str)\n",
    "subset_preds['encoded_label'] = metadata['treatmentstatus'].apply({\"naive\":0, \"treated\":1}.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing scores \n",
    "We need to compute AMI and/or balanced accuracy for the RF/LR/NB and fisher test based classifier on the 3 tasks. showing everything: \n",
    " - trained on B, tested on C\n",
    " - trained on C, tested on B\n",
    " - trained on ALL, tested on Africa\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(df):\n",
    "    scorer = {'AMI':adjusted_mutual_info_score, 'bal acc':balanced_accuracy_score, 'accuracy':accuracy_score}\n",
    "    scores = {}\n",
    "    for name, function in scorer.items():\n",
    "        scores[name] = function(df['real'], df['pred'])\n",
    "    return pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvalue(df):\n",
    "    N = df.shape[0]\n",
    "    m_i = mutual_info_score(df['real'], df['pred'])\n",
    "    G_stat = m_i * 2 * N \n",
    "    return 1 - chi2.cdf(G_stat, df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores_cleaned: the sequences with DRMs are removed from the test set for models trained without them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = subset_preds.groupby(grouper).apply(get_scores)\n",
    "p_values = subset_preds.groupby(grouper).apply(get_pvalue).rename('p_value').reset_index()\n",
    "melted = pd.melt(scores.reset_index(), id_vars=grouper)\n",
    "melted['group'] = melted['task'] + ' ' + melted['subtype']\n",
    "melted['group2'] = melted['target'] + ' ' + melted['subtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonferroni(df, alpha=0.05):\n",
    "    N = df.shape[0]\n",
    "    df['bonferroni'] = df['p_value'] <= (alpha / N)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = p_values.groupby('subtype').apply(bonferroni).set_index(['subtype', 'task', 'shorthand', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['NB', 'LR', 'RF', 'FC']\n",
    "subtypes = ['ALL', 'B', 'C']\n",
    "subtype_labels = {\n",
    "    'ALL': 'trained on UK B&C,\\ntested on Africa',\n",
    "    'B': 'trained on UK B,\\ntested on UK C',\n",
    "    'C': 'trained on UK C,\\ntested on UK B'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [color for color in sns.palettes.color_palette('muted') for _ in range(3)]\n",
    "hue_order = [f\"{task} {sub}\" for task in task_order for sub in subtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = {'big': 3, 'small':4}\n",
    "patterns = {k:{'B':'/'*n, 'C': '\\\\'*n} for k,n in repeats.items()} \n",
    "hatches = [patterns['big'].get(sub, None) for task in task_order for sub in subtypes for model in models]\n",
    "small_hatches = [patterns['small'].get(sub, None) for task in task_order for sub in subtypes for model in models]\n",
    "hatches_multi = [patterns['big'].get(sub, None) for sub in subtypes for target in target_order for model in models]\n",
    "small_hatches_multi = [patterns['small'].get(sub, None) for sub in subtypes for target in target_order for model in models]\n",
    "models_ext = models + ['RD']\n",
    "hatches_ext = [patterns.get(sub, None) for task in task_order for sub in subtypes for model in models_ext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "sns.set_palette('muted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend(gen_label=False, context='notebook', hue='task'):\n",
    "    with sns.plotting_context(context):\n",
    "        hues = {\n",
    "            'task': ['all features\\nkept\\n', 'RAM features\\nremoved\\n'],\n",
    "            'target': ['\\ntreated vs. naive\\n', '\\nw/ RAM vs. wo/ RAM\\n']\n",
    "        }\n",
    "        h1 = [Patch(facecolor=color, label=label, edgecolor='black') \n",
    "                for label, color in zip(hues.get(hue, []), sns.color_palette())]\n",
    "        h2 = [Patch(facecolor=\"white\",label=subtype_labels.get(subtype),hatch=patterns['small'].get(subtype, \"\"), \n",
    "                edgecolor='black',) for subtype in subtypes]\n",
    "        l = Line2D([0], [0], color='red', label=\"expected value\\nfor null classifier\\n\")\n",
    "        e = Patch(color='white', label=\"\")\n",
    "        labels = [Patch(color=\"white\", label=\"signal removal:\\n\\n\"), Patch(color=\"white\", label=\"training scenario:\\n\")]\n",
    "    (ncol, handles) = (5, labels) if gen_label else (3, [])\n",
    "    return (ncol, \n",
    "        handles + [h1[0], h2[0]] + [h1[1], h2[1]] + [l, h2[2]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subplot(to_plot, ylabel, annots=None, x='shorthand', y='value', hue='group', order=models, palette=colors, hue_order=hue_order, hatches=hatches, ax=None, title=\"\", title_args=dict(), yticks=None, ylim=None, log=False, xlabel=\"Classifier\"):\n",
    "    \n",
    "    kwargs={'ax':ax} if ax is not None else {}\n",
    "        \n",
    "    ax = sns.barplot(\n",
    "        data=to_plot, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        hue=hue, \n",
    "        order=order,\n",
    "        hue_order=hue_order, \n",
    "        palette=palette, \n",
    "        # lw=1.2,\n",
    "        edgecolor='black',\n",
    "        ci=None,\n",
    "        **kwargs\n",
    "    )\n",
    "    if annots is None:\n",
    "        annots = [\"\" for _ in hatches]\n",
    "    for patch, hatch, annot in zip(ax.patches, hatches, annots):\n",
    "        if annot == \"*\":\n",
    "            x = patch.get_x() + patch.get_width() / 2\n",
    "            if log:\n",
    "                y = (patch.get_y() + patch.get_height()) * 1.05\n",
    "            else:\n",
    "                y = (patch.get_y() + patch.get_height()) + 0.01\n",
    "            ax.text(x, y, annot, ha='center', va='center')\n",
    "        if hatch is None:\n",
    "            continue \n",
    "        patch.set_hatch(hatch)\n",
    "\n",
    "    sns.despine()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_title(title, **title_args)\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_brace(ax, xspan, yy, text):\n",
    "    \"\"\"Draws an annotated brace on the axes.\"\"\"\n",
    "    xmin, xmax = xspan\n",
    "    xspan = xmax - xmin\n",
    "    ax_xmin, ax_xmax = ax.get_xlim()\n",
    "    xax_span = ax_xmax - ax_xmin\n",
    "\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    yspan = ymax - ymin\n",
    "    resolution = int(xspan/xax_span*100)*2+1 # guaranteed uneven\n",
    "    beta = 300./xax_span # the higher this is, the smaller the radius\n",
    "\n",
    "    x = np.linspace(xmin, xmax, resolution)\n",
    "    x_half = x[:int(resolution/2)+1]\n",
    "    y_half_brace = (1/(1.+np.exp(-beta*(x_half-x_half[0])))\n",
    "                    + 1/(1.+np.exp(-beta*(x_half-x_half[-1]))))\n",
    "    y = np.concatenate((y_half_brace, y_half_brace[-2::-1]))\n",
    "    y = yy + (.05*y - .01)*yspan # adjust vertical position\n",
    "\n",
    "    ax.autoscale(False)\n",
    "    ax.plot(x, y, color='black', lw=1)\n",
    "\n",
    "    ax.text((xmax+xmin)/2., yy+.07*yspan, text, ha='center', va='bottom', rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "mpl.rcParams['hatch.linewidth'] = 0.4\n",
    "mult = 1.5\n",
    "fig = plt.figure(figsize=(8.3 * mult, 5.8))\n",
    "annots = [\"*\" if corrected['bonferroni'].get((sub, task_order[1], model, target), False) else \"\"\n",
    "                for sub in subtypes for target in target_order for model in models]\n",
    "title_args = {'loc':'left', 'fontweight':'bold', 'pad':0}\n",
    "hue_order_multi = [f\"{target} {subtype}\" for subtype in subtypes for target in target_order]\n",
    "colors_multi = [col for _ in subtypes for col in (sns.color_palette()[:2])]\n",
    "ami_ticks = np.linspace(0, 0.55, 12)\n",
    "acc_ticks = np.linspace(0.5, 0.6, 2)\n",
    "\n",
    "to_plot_AMI = melted[(melted['shorthand'].isin(models)) & (melted['variable'] == 'AMI') & (melted['task'] == task_order[1])]\n",
    "to_plot_bal = melted[(melted['shorthand'].isin(models)) & (melted['variable'] == 'bal acc') & (melted['task'] == task_order[1])]\n",
    "\n",
    "to_plot_AMI.to_csv(os.path.join(dirname, \"Fig_2_a.csv\"), header=True, index=True)\n",
    "to_plot_bal.to_csv(os.path.join(dirname, \"Fig_2_b.csv\"), header=True, index=True)\n",
    "\n",
    "with sns.axes_style('white', {'grid.color':'.8', 'axes.grid':True, 'ytick.left':True}):\n",
    "    ax1 = plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=2)\n",
    "    get_subplot(to_plot_AMI, 'Adjusted Mutual Information (log scale)', annots=annots, ax=ax1, title='  a)', \n",
    "                title_args=title_args, yticks=ami_ticks, ylim=(1e-3, 1.5), log=True, hue='group2', hue_order=hue_order_multi, hatches=hatches_multi, palette=colors_multi, xlabel=\"\")\n",
    "    ax2 = plt.subplot2grid((3, 3), (0, 2), rowspan=2)\n",
    "    ax2.axhline(y=0.5, ls='-', color='red', zorder=0.9)\n",
    "    get_subplot(to_plot_bal, 'Balanced Accuracy', ax=ax2, title='  b)', title_args=title_args, \n",
    "                yticks=acc_ticks, hatches=small_hatches_multi, ylim=(0.45,0.65), xlabel=\"\", hue='group2', hue_order=hue_order_multi, palette=colors_multi)\n",
    "\n",
    "ax1.grid(b=True, which='minor', color='.8', lw=0.2)\n",
    "\n",
    "patch_order = [(sub, model) for sub in subtypes for target in target_order for model in models ]\n",
    "brace_xs = defaultdict(list)\n",
    "\n",
    "for patch, (sub, model) in zip(ax1.patches, patch_order):\n",
    "    brace_xs[(sub, model)].append((patch.get_x(), patch.get_width()))\n",
    "\n",
    "for (sub, _), pos in brace_xs.items():\n",
    "    draw_brace(ax1, (pos[0][0]+0.01, sum(pos[1])-0.01), 0.1, {'ALL': ' Africa', 'B': ' UK C', 'C': ' UK B'}.get(sub))\n",
    "\n",
    "ax3 = plt.subplot2grid((3, 3), (2, 0), colspan=3)\n",
    "ax3.axis('off')\n",
    "\n",
    "ncol, handles = get_legend(hue='target')\n",
    "ax3.legend(handles=handles, ncol=ncol,  bbox_to_anchor=(0.5, 0.5), loc='center', borderaxespad=0, frameon=False)\n",
    "fig.savefig(os.path.join(dirname, 'performance_compare_tasks.pdf'), format='pdf', alpha=.99, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(dirname, 'performance_compare_tasks.eps'), format='eps', alpha=.99, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
