# Included data

## Training data
Some data used in the pipelines is included in this repository. 

### Sequence data
The HIV-1 *pol* RT **DNA** sequence alignments from the African dataset produced by [Villabona-Arenas et al. (2016)](https://doi.org/10.1097/QAD.0000000000001233) are available in this repository, in the `African_dataset` directory.  
2 FASTA sequence files are made available: 
 - `naive.fa` contains sequences extracted from RTI-naive individuals
 - `treated.fa` contains sequences extracted from RTI-experienced individuals

The HIV-1 *pol* RT **Protein** sequence alignments from the UK dataset were made available by the [UK HIV Drug Resistance Database](https://www.hivrdb.org.uk/). They are stored in the `UK_dataset`directory with the same 2 FASTA files as the African dataset.

DNA sequence data from the UK dataset used to train the classifiers could not be included in this repository, however the UK HIV Drug Resistance Database can make information available to any bona fide researcher who submits a scientifically robust proposal, provided data exchange complies with Information Governance and Data Security Policies in all the relevant countries. Inquiries should be addressed to [iph.hivrdb@ucl.ac.uk](mailto:iph.hivrdb@ucl.ac.uk).
### Metadata
The metadata files for both the UK and the African datasets are made available in this repository. 
Each file is a tab separated value file that contains the following fields:
  - `id`: the identifier of the sequence
  - `treatmentstatus`: whether the sequence comes from a naive or treated individual (`"naive" | "treated"`)
  - `hasDRM`: whether the sequence contains any known DRMs/RAMs or not (`"0" | "1"`)
  - `subtype`: the subtype or CRF of the sequence.

## Result data
Some outputs of the pipelines, useful to run the figure generation notebooks are also made available in this repository. 

### Base experiment results
The results included in the `results/Base_results` directory are generated by training classifiers on the binary *naive/treated* classification task. The following training / testing sets were used: 
  1. Train on UK subtype B, test on UK subtype C
  2. Train on UK subtype C, test on UK subtype C
  3. Train on UK subtypes B & C, test on Africa all subtypes and CRFs

Additionaly, each training was repeated with 3 levels of signal removal:
  1. No signal removed, all features and sequences kept in training set
  2. Features corresponding to known DRMs/RAMs were removed from the training and testing sets
  3. Features and sequences containing known DRMs/RAMs were removed from the training as testing sets

This resulted in 9 training / testing schemas *(cf. Table 2 in manuscript)*.
On each of these schemas the following classifiers were trained/ tested

  - Random Forest
  - Naive Bayes
  - Logistic Regression with Lasso L1 regularization
  - A Fisher test based classifier (with different corrections for multiple testing)
  - A simple classifier that checks if at least n known DRMs/RAMs are present in the sequence

More details on these classifiers can be obtained [here](https://github.com/lucblassel/utils_hiv/blob/master/utils_hiv/utils/learning_utils.py#L48)

The `all_preds.tsv` file contains predictions for the testing sets of the 9 schemas, made by all the trained models.  
The `coefs_df.tsv` file contains the feature importance values extracted from all the trained models.  
The `preds_total.tsv` file contains the predicted class probabilities for all the testing sets (for models that have probabilistic prediction capabilities)

These predictions were used to create Figure 1 of the manuscript

### Alternate_target_results
The results included in `results/Alternate_target_results` were obtained by training classifiers on the following 2 classification tasks: 

  1. binary treated / naive classification task
  2. binary known DRM presence / absence classification task

The trainings were done on the same 3 training / testing sets as above but with only the second level of signal removal (ie. features corresponding to known DRMs/RAMs removed from datasets)

The same classifiers as above were trained and used to generate the results. 
The resulting files are the same as above. 

These predictions were used to create Figure 2 of the manuscript

